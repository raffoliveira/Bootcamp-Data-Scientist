{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação de pacote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pacote básico\n",
    "import tweepy # Acesso API do Twitter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição das credenciais de acesso#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credenciais para utilização da API do Twitter\n",
    "API_Key =\"\"\n",
    "API_secret_key = \"\"\n",
    "Access_token = \"\"\n",
    "Access_token_secret = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autenticação na API do Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizar autenticação no Twitterr\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_key,API_secret_key)\n",
    "auth.set_access_token(Access_token,Access_token_secret)\n",
    "\n",
    "#Construindo a instancia da API - \n",
    "api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True,\n",
    "                 retry_count=5,retry_delay=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coleta de dados (busca por palavra chave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir listas de armazenamento\n",
    "tweets =[]\n",
    "info =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definir que palavras (keyword) que deseja pesquisar no Twitter\n",
    "\n",
    "#keyword = ('#homeoffice OR #trabalhoremoto')\n",
    "#keyword = (''home office' OR 'trabalho remoto' OR 'trabalho em casa' OR homeoffice OR trabalhoremoto')\n",
    "keyword = ('covid-19 OR covid OR coronavirus OR pandemic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busca por palavra chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.seach,\n",
    "                           q=keyword, tweet_mode='extented',\n",
    "                           rpp=1000, result_type=\"mixed\",lang='en',\n",
    "                           include_entitiews=True).items(1000):\n",
    "    \n",
    "    if 'retweeted_status' in dir(tweet):\n",
    "        aux=tweet.retweeted_status.full_text\n",
    "    else:\n",
    "        aux=tweet.full_text\n",
    "    \n",
    "    newtweet = aux.replace(\"\\n\",\" \")\n",
    "    \n",
    "    tweets.append(newtweet)\n",
    "    info.append(tweet)\n",
    "    file = open(\"tweets_Keyword_covid_en_turma2.txt\",\"a\", -1,\"utf-8\")\n",
    "    file.write(newtweet+'\\n')\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantidade de twitters coletados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para verificar a quantidade de tweets coletados use a funçao len()\n",
    "print(\"Total de tweets coletados %s. \" % (len(info)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria o dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame(tweets, columns=['Tweets'])\n",
    "tweets_df['len']= np.array([len(tweet) for tweet in tweets])\n",
    "tweets_df['ID']= np.array([tweet.id for tweet in info])\n",
    "tweets_df['USER']= np.array([tweet.user.screen_name for tweet in info])\n",
    "tweets_df['useName']= np.array([tweet.user.name for tweet in info])\n",
    "tweets_df['User Location']= np.array([tweet.user.location for tweet in info])\n",
    "tweets_df['Language']=np.array([tweet.user.lang for tweet in info])\n",
    "tweets_df['Date']=np.array([tweet.created_at for tweet in info])\n",
    "tweets_df['Source']=np.array([tweet.source for tweet in info])\n",
    "tweets_df['Likes']=np.array([tweet.favorite_count for tweet in info])\n",
    "tweets_df['Retweets']=np.array([tweet.retweet_count for tweet in info])\n",
    "tweets_df['Geo']=np.array([tweet.geo for tweet in info])\n",
    "tweets_df['Coordinates']=np.array([tweet.coordinates for tweet in info])\n",
    "tweets_df['Place']=np.array([tweet.place for tweet in info])\n",
    "\n",
    "tweets_df.to_csv(\"tweets100_keyword_HomeOffice_Turma2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificar Top Tweets coletados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets com maior numero de LIkes\n",
    "likes_max = np.max(tweets_df['Likes']) # funçao max do numpy identifica o valor maximo\n",
    "\n",
    "likes = tweets_df[tweets_df.Likes == likes_max].index[0] # pega o primeiro tweet com valor maximo\n",
    "\n",
    "print(\"o tweet com mais curtidas (likes) é: \\n{}\".format(tweets_df[Tweets][likes]))\n",
    "print(\"Numero de curtidas: {}\".format(likes_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prin(np.sum(tweets_df['Likes'] == likes_max) #conta tweets possuem o mesmo valor maximo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets com maior numero de retweets\n",
    "retweet_max = np.max(tweets_df['Retweets']) # funçao max do numpy identifica o valor maximo\n",
    "\n",
    "retweet = tweets_df[tweets_df.Retweets == retweet_max].index[0] # pega o primeiro tweet com valor maximo\n",
    "\n",
    "print(\"o tweet com mais recurtidas (retweets) é: \\n{}\".format(tweets_df[Tweets][retweet]))\n",
    "print(\"Numero de recurtidas: {}\".format(retweet_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prin(np.sum(tweets_df['Retweets'] == retweet_max) #conta tweets possuem o mesmo valor maximo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifica a fonte(origem) do tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "for source in tweets_df['Source']:\n",
    "    if source not in sources:\n",
    "        sources.append(source) # inclui somente se não existir\n",
    "    \n",
    "percent = np.zeros(len(sources))\n",
    "\n",
    "for source in tweets_df['Source']:\n",
    "    for index in range(len(sources)):\n",
    "        if source == sources[index]:\n",
    "            percent[index] += 1\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafico que exibe o numero de tweets por fonte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceDF = pd.DataFrame({\n",
    "    'source':percent,\n",
    "},index=sources)\n",
    "\n",
    "sourceDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pacote para visualização\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_sorted = sourceDF.sort_values('source',ascending=True)\n",
    "ax = sources_sorted.source.plot(kind='barh',color='#a52a2a')\n",
    "ax.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources_sorted = sourceDF.sort_values('source',ascending=False)\n",
    "ax = sources_sorted.source.plot(kind='barh',color='#b8860b')\n",
    "ax.get_xaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANALISE DE POLARIDADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variavel que ira armazer as polaridades\n",
    "analysis = None\n",
    "# Lista vazia para armazenar as polaridades\n",
    "polarities =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula a polaridade (entiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets_df['Tweets']: para cada tweet\n",
    "    analysis = tb(tweet)\n",
    "    \n",
    "    polarity = analysis.sentiment.polarity #analisa a polaridade\n",
    "    \n",
    "    polarities.append(polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets_df['Tweets']: para cada tweet\n",
    "    \n",
    "    polarity = tb(tweet).sentiment.polarity #analisa a polaridade\n",
    "    \n",
    "    polarities.append(polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vetor de polaridade: \", polarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise de Sentimentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Para as palavras :\"%s\"' % keyword)\n",
    "print('A média de sentimento é: ' + str(np.mean(polarities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive =0\n",
    "negative =0\n",
    "neutral = 0\n",
    "\n",
    "for polarity in polarities:\n",
    "    if polarity > 0:\n",
    "        positive =  positive+1\n",
    "    elif polarity < 0:\n",
    "        negative = negative+1\n",
    "    else:\n",
    "        neutral = neutral+1\n",
    "\n",
    "#print(\"Tweets Positivos: %s\" % positive)\n",
    "#print(\"Tweets Negativos: %s\" % negative)\n",
    "#print(\"Tweets Neutros: %s\" % neutral)\n",
    "\n",
    "#Calcula percentual\n",
    "pos_pct=positive*100/len(polarities)\n",
    "neg_pct=negative*100/len(polarities)\n",
    "neu_pct=neutral*100/len(polarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define variaveis\n",
    "sentiments =['Positivos','Negativos','Neutros']\n",
    "percents =[pos_pct,neg_pct,neu_pct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um array (series) denomnado pir_chart com os vlaores da variavel percents\n",
    "# onde o indice do array equivale aos valors da variavel sentiments.\n",
    "\n",
    "pie_chart = pd.Series(percents,index=sentiments,name='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar (plotar) o grafico de pissa (torta)\n",
    "pie_chart.plot.pie(fontsize=12, autopct='%.2f', figsize=(5,5), labels=pie_chart.index, \n",
    "                   title=\"Análise de Sentimentos tweets\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tipos de graficos diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar (plotar) o grafico de pissa (torta)\n",
    "explode = (0.1,0,0) # separa o primeiro indexe\n",
    "\n",
    "pie_chart.plot.pie(fontsize=12, explode=explode,autopct='%.2f', shadow=True,\n",
    "                   figsize=(5,5), labels=pie_chart.index, \n",
    "                   title=\"Análise de Sentimentos tweets\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando pacote MatplotLib\n",
    "\n",
    "patches,text = plt.pie(percents,startangle=90)\n",
    "plt.legend(patches, sentiments, loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando pacote Matpltolib 2\n",
    "colors =['yellowgreen','lightskyblue','lightcoral'] # personaliza as cores\n",
    "\n",
    "patches,text = plt.pie(percents,colors=colors,startangle=90)\n",
    "plt.legend(patches, sentiments, loc=\"best\")\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapa de calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trabalhando com mapas\n",
    "from geopy.geocoders import Nominatim\n",
    "# import folium\n",
    "from folium import plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos enteder o funcionamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = Nominatim(user_agent =\"TweeterSentiments\")\n",
    "exemplo = locator.geocode(\"Belo Horizonte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplo.latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplo.longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo do twiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"TweeterSentiments\")\n",
    "\n",
    "#Lista para armazenar a latitude e longitude\n",
    "latitute=[]\n",
    "longitude=[]\n",
    "\n",
    "for user_location in tweets_df['User Location']:\n",
    "    try:\n",
    "        location = geolocator.geocode(user_location)\n",
    "        latitude.append(location.latitude)\n",
    "        longitude.append(location.longitude)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordenadas = np.column_stack((latide,longitude))\n",
    "\n",
    "mapa = folium.Map(zoom_start=3.)\n",
    "mapa.add_child(plugins.HeatMap(coordenadas))\n",
    "mapa.save('Mapa_calor_covid_en_Turma2.html')\n",
    "mapa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapa de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos entender algumas funçoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' segunda aula interativa. @Fernanda. #igti. Aula sobre Coleta e obtenção de dadosdo bootcamp de Cientista de Dados do IGTI. https://www.igti.com.br/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenca =\" segunda aula interativa. @Fernanda. #igti. Aula sobre Coleta e obtenção de dados\\\n",
    "do bootcamp de Cientista de Dados do IGTI. https://www.igti.com.br/\"\n",
    "sentenca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['segunda',\n",
       " 'aula',\n",
       " 'interativa.',\n",
       " '@Fernanda.',\n",
       " '#igti.',\n",
       " 'Aula',\n",
       " 'sobre',\n",
       " 'Coleta',\n",
       " 'e',\n",
       " 'obtenção',\n",
       " 'de',\n",
       " 'dadosdo',\n",
       " 'bootcamp',\n",
       " 'de',\n",
       " 'Cientista',\n",
       " 'de',\n",
       " 'Dados',\n",
       " 'do',\n",
       " 'IGTI.',\n",
       " 'https://www.igti.com.br/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformando em palvras\n",
    "palavras = sentenca.split()\n",
    "palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras=[]\n",
    "for palavra in sentenca.split():\n",
    "    if 'https' not in palavra and not palavra.startswith('@') and not palavra.startswith('#'):\n",
    "        palavras.append(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-5a1bbaf49317>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m               \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m               \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m               normalize_plurals= True).generate(palavras)\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"bilinear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \"\"\"\n\u001b[1;32m--> 631\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \"\"\"\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[0mregexp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34mr\"\\w[\\w']+\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m         \u001b[1;31m# remove 's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         words = [word[:-2] if word.lower().endswith(\"'s\") else word\n",
      "\u001b[1;32m~\\.conda\\envs\\dev\\lib\\re.py\u001b[0m in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[1;32m--> 223\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "wc = WordCloud(min_font_size=10,\n",
    "              max_font_size=300,\n",
    "              background_color='blue',\n",
    "              mode=\"RGB\",\n",
    "              width=2000,\n",
    "              height=1000,\n",
    "              normalize_plurals= True).generate(palavras)\n",
    "\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('covid_cloud_pt_Turma2.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
